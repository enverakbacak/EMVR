{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "videoGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNPka6X5epKEfYD7SLFaRAu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enverakbacak/EMVR/blob/main/videoGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLG0sGzXxRyk",
        "outputId": "f25600db-8f96-4a55-8f3a-9ec37a94558e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-TRry6Uxegf",
        "outputId": "264ba23c-537a-4fd8-a5e0-c37b5b63efcf"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q6Rq7gIxgxQ",
        "outputId": "d7678eec-9a28-4da6-a796-470a511d3a76"
      },
      "source": [
        "cd drive/MyDrive/ColabNotebooks/video_generators/\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks/video_generators\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yd0sfYvt54b"
      },
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import sys,os\n",
        "import time\n",
        "import matplotlib\n",
        "import scipy.io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow.keras.optimizers\n",
        "from tensorflow.keras import Input \n",
        "from tensorflow.keras.models import Model\n",
        "#Inputlayer\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, TimeDistributed, Conv2D, MaxPool2D, LSTM, Bidirectional, BatchNormalization\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.models import load_model\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "from skimage.transform import resize   # for resizing images\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import math"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ4nnV0TxqXn"
      },
      "source": [
        "batch_size = 1\n",
        "resize     = 224\n",
        "\n",
        "def generator(samples, labels, batch_size=batch_size):\n",
        "    \"\"\"\n",
        "    Yields the next training batch.\n",
        "    Suppose `samples` is an array [[image1_filename,label1], [image2_filename,label2],...].\n",
        "    \"\"\"\n",
        "    num_samples = len(samples)\n",
        "  \n",
        "    while True: # Loop forever so the generator never terminates\n",
        "\n",
        "        # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size &lt;= num_samples]\n",
        "        for offset in range(0, num_samples, batch_size):\n",
        "            # Get the samples you'll use in this batch\n",
        "            batch_samples = samples[offset:offset+batch_size]\n",
        "            label_samples = labels[offset:offset+batch_size]\n",
        "            # Initialise X_train and y_train arrays for this batch\n",
        "           \n",
        "            y = []\n",
        "            X = []\n",
        "            # For each example\n",
        "            for batch_sample in batch_samples:\n",
        "              #filename = batch_sample\n",
        "                cap = cv2.VideoCapture(batch_sample)\n",
        "                fps = cap.get(cv2.CAP_PROP_FPS)      # OpenCV2 version 2 used \"CV_CAP_PROP_FPS\"\n",
        "                frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "                duration = frame_count/fps\n",
        "                N = 10 # How many frames will be extracted\n",
        "                interwall = duration/N   #//it will capture image in each 'interwall' second\n",
        "                           \n",
        "                sec = 0                          \n",
        "                frames = []\n",
        "                for frame in range(0,N,1):\n",
        "                  cap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
        "                  sec = sec + interwall\n",
        "                  ret, frame = cap.read()\n",
        "                  frame = cv2.resize(frame,(resize, resize))\n",
        "                  frames.append(frame) \n",
        "                X.append(frames)\n",
        "                                                       \n",
        "            X = np.array(X)\n",
        "            X.shape\n",
        "            #print(X.shape[:])\n",
        "            X = X.astype(float)\n",
        "            X = X / 255\n",
        "            #X = X.reshape(X.shape[0], X.shape[1] , X.shape[2] * X.shape[3] * X.shape[4])\n",
        "            #print(X.shape[:])\n",
        "                                   \n",
        "            for label_sample in label_samples:\n",
        "                y.append(label_sample)\n",
        "            y = np.array(y)\n",
        "            y = y.astype(float)\n",
        "            #print(y.dtype)\n",
        "\n",
        "            # The generator-y part: yield the next training batch\n",
        "            yield X, y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQiGS9yuxrGo"
      },
      "source": [
        "data=[]\n",
        "from csv import reader\n",
        "# skip first line i.e. read header first and then iterate over each row od csv as a list\n",
        "with open('trainlist01.csv', 'r') as read_obj:\n",
        "    csv_reader = reader(read_obj)\n",
        "    header = next(csv_reader)\n",
        "    # Check file as empty\n",
        "    if header != None:\n",
        "        # Iterate over each row after the header in the csv\n",
        "        for row in csv_reader:\n",
        "            # row variable is a list that represents a row in csv\n",
        "            data.append(row)\n",
        "data=np.array(data)\n",
        "videos = data[:,0]\n",
        "\n",
        "labels = data[:,1]\n",
        "labels = labels.astype(int)\n",
        "labels_onehot = LabelBinarizer().fit_transform(labels)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yFir5YQGPSE"
      },
      "source": [
        "train_generator = generator(videos, labels_onehot, batch_size=batch_size)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPHWSaWeGHKr",
        "outputId": "80ed84ef-5987-4e87-8b52-62d0c86a0511"
      },
      "source": [
        "x,y = next(train_generator)\n",
        "print ('data shape: ', x.shape[:])\n",
        "print ('label shape: ', y.shape)\n",
        "print(x.dtype)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data shape:  (1, 10, 224, 224, 3)\n",
            "label shape:  (1, 101)\n",
            "float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ0faacn4Cpl",
        "outputId": "18cb0d75-c7fb-4fdc-bc89-f8056a1b0132"
      },
      "source": [
        "hash_bits = 64\n",
        "\n",
        "video_input = tensorflow.keras.Input(shape = (10,resize,resize,3), name='video')\n",
        "\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, pooling='avg') # input_shape=(X.shape[1:])\n",
        "base_model.trainable = False\n",
        "\n",
        "frame_features = layers.TimeDistributed(base_model)(video_input)\n",
        "blstm_1   = Bidirectional(LSTM(512, dropout=0.1, recurrent_dropout=0.5, return_sequences = True  ))(frame_features)\n",
        "blstm_2   = Bidirectional(LSTM(512, dropout=0.1, recurrent_dropout=0.5, return_sequences = False ))(blstm_1)\n",
        "batchNorm = BatchNormalization()(blstm_2)\n",
        "Dense_1   = Dense(256)(batchNorm)\n",
        "Dense_2   = Dense(hash_bits, activation = 'sigmoid' )(Dense_1)\n",
        "#batchNorm = BatchNormalization()(Dense_2)\n",
        "Dense_3   = Dense(101, activation='sigmoid')(Dense_2)\n",
        "model     = Model(video_input, Dense_3)\n",
        "print(model.summary())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "video (InputLayer)           [(None, 10, 224, 224, 3)] 0         \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 10, 2048)          21802784  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 10, 1024)          10489856  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 1024)              6295552   \n",
            "_________________________________________________________________\n",
            "batch_normalization_94 (Batc (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 101)               6565      \n",
            "=================================================================\n",
            "Total params: 38,877,701\n",
            "Trainable params: 17,072,869\n",
            "Non-trainable params: 21,804,832\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IFe6beM66FO"
      },
      "source": [
        "sgd = SGD(learning_rate=0.01, decay = 1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "def c_loss_1(y_true, y_pred):\n",
        "    return  tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "\n",
        "def c_loss_2(noise_1, noise_2):\n",
        "    noise_1 = tf.cast(Dense_2 > 0.5 , tf.float32 )\n",
        "    noise_2 = Dense_2\n",
        "    return  tf.keras.losses.binary_crossentropy(noise_1, noise_2)\n",
        "model.compile(loss = [c_loss_1, c_loss_2],  optimizer=sgd, metrics=['accuracy'],)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59fLSu3v7NYR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8babfd28-7cad-44a3-9568-6fe18cf2f9ba"
      },
      "source": [
        "model.fit_generator(train_generator, \n",
        "                    steps_per_epoch  = math.ceil(len(videos) // batch_size), \n",
        "                    #validation_data=val_generator,\n",
        "                    #validation_steps = math.ceil(len(val_data) // batch_size),\n",
        "                    verbose=1, \n",
        "                    epochs=300)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            " 686/9536 [=>............................] - ETA: 1:36:05 - loss: 0.2311 - accuracy: 0.2711"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}