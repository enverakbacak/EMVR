{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "videoGenerator.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMVXdvOC3cip0EmED050DFa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enverakbacak/EMVR/blob/main/videoGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLG0sGzXxRyk",
        "outputId": "bf9ee994-b239-4baa-cebc-c57c99fa4c1f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-TRry6Uxegf",
        "outputId": "54553005-b9b7-4b0c-8ca5-b8de339ee8cd"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q6Rq7gIxgxQ",
        "outputId": "610e7d0f-3161-4474-ce10-68457d31cb04"
      },
      "source": [
        "cd drive/MyDrive/ColabNotebooks/video_generators/\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks/video_generators\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yd0sfYvt54b"
      },
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import sys,os\n",
        "import time\n",
        "import matplotlib\n",
        "import scipy.io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow.keras.optimizers\n",
        "from tensorflow.keras import Input \n",
        "from tensorflow.keras.models import Model\n",
        "#Inputlayer\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, TimeDistributed, Conv2D, MaxPool2D, LSTM, Bidirectional, BatchNormalization\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.models import load_model\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use('Agg')\n",
        "from skimage.transform import resize   # for resizing images\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import math"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ4nnV0TxqXn"
      },
      "source": [
        "batch_size = 1\n",
        "resize     = 224\n",
        "\n",
        "def generator(samples, labels, batch_size=batch_size):\n",
        "    \"\"\"\n",
        "    Yields the next training batch.\n",
        "    Suppose `samples` is an array [[image1_filename,label1], [image2_filename,label2],...].\n",
        "    \"\"\"\n",
        "    num_samples = len(samples)\n",
        "  \n",
        "    while True: # Loop forever so the generator never terminates\n",
        "\n",
        "        # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size &lt;= num_samples]\n",
        "        for offset in range(0, num_samples, batch_size):\n",
        "            # Get the samples you'll use in this batch\n",
        "            batch_samples = samples[offset:offset+batch_size]\n",
        "            label_samples = labels[offset:offset+batch_size]\n",
        "            # Initialise X_train and y_train arrays for this batch\n",
        "           \n",
        "            y = []\n",
        "            X = []\n",
        "            # For each example\n",
        "            for batch_sample in batch_samples:\n",
        "              #filename = batch_sample\n",
        "                cap = cv2.VideoCapture(batch_sample)\n",
        "                fps = cap.get(cv2.CAP_PROP_FPS)      # OpenCV2 version 2 used \"CV_CAP_PROP_FPS\"\n",
        "                frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "                duration = frame_count/fps\n",
        "                N = 10 # How many frames will be extracted\n",
        "                interwall = duration/N   #//it will capture image in each 'interwall' second\n",
        "                           \n",
        "                sec = 0                          \n",
        "                frames = []\n",
        "                for frame in range(0,N,1):\n",
        "                  cap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
        "                  sec = sec + interwall\n",
        "                  ret, frame = cap.read()\n",
        "                  frame = cv2.resize(frame,(resize, resize))\n",
        "                  frames.append(frame) \n",
        "                X.append(frames)\n",
        "                                                       \n",
        "            X = np.array(X)\n",
        "            X.shape\n",
        "            print(X.shape[:])\n",
        "            X = X.astype(float)\n",
        "            X = X / 255\n",
        "            X = X.reshape(X.shape[0], X.shape[1] , X.shape[2] * X.shape[3] * X.shape[4])\n",
        "            print(X.shape[:])\n",
        "                                   \n",
        "            for label_sample in label_samples:\n",
        "                y.append(label_sample)\n",
        "            y = np.array(y)\n",
        "            y = y.astype(float)\n",
        "            #print(y.dtype)\n",
        "\n",
        "            # The generator-y part: yield the next training batch\n",
        "            yield X, y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQiGS9yuxrGo"
      },
      "source": [
        "data=[]\n",
        "from csv import reader\n",
        "# skip first line i.e. read header first and then iterate over each row od csv as a list\n",
        "with open('trainlist01.csv', 'r') as read_obj:\n",
        "    csv_reader = reader(read_obj)\n",
        "    header = next(csv_reader)\n",
        "    # Check file as empty\n",
        "    if header != None:\n",
        "        # Iterate over each row after the header in the csv\n",
        "        for row in csv_reader:\n",
        "            # row variable is a list that represents a row in csv\n",
        "            data.append(row)\n",
        "data=np.array(data)\n",
        "videos = data[:,0]\n",
        "\n",
        "labels = data[:,1]\n",
        "labels = labels.astype(int)\n",
        "labels_onehot = LabelBinarizer().fit_transform(labels)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yFir5YQGPSE"
      },
      "source": [
        "train_generator = generator(videos, labels_onehot, batch_size=batch_size)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPHWSaWeGHKr",
        "outputId": "a6f4c6c2-3272-4f14-cbd4-264d0eb81257"
      },
      "source": [
        "x,y = next(train_generator)\n",
        "print ('data shape: ', x.shape)\n",
        "print ('label shape: ', y.shape)\n",
        "print(x.dtype)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 10, 224, 224, 3)\n",
            "(1, 10, 150528)\n",
            "data shape:  (1, 10, 150528)\n",
            "label shape:  (1, 101)\n",
            "float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ0faacn4Cpl",
        "outputId": "8b8fed95-ff92-4152-a741-d55865690373"
      },
      "source": [
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(resize,resize,3)) # input_shape=(X.shape[1:])\n",
        "base_model.trainable = True\n",
        "hash_bits = 64\n",
        "\n",
        "visible   = Input(shape = (batch_size , resize*resize*3))\n",
        "blstm_1   = Bidirectional(LSTM(512, dropout=0.1, recurrent_dropout=0.5, input_shape=(batch_size , resize*resize*3), return_sequences = True  ))(visible)\n",
        "blstm_2   = Bidirectional(LSTM(512, dropout=0.1, recurrent_dropout=0.5, input_shape=(batch_size , resize*resize*3), return_sequences = False ))(blstm_1)\n",
        "batchNorm = BatchNormalization()(blstm_2)\n",
        "Dense_1   = Dense(256)(batchNorm)\n",
        "Dense_2   = Dense(hash_bits, activation = 'sigmoid' )(Dense_1)\n",
        "#batchNorm = BatchNormalization()(Dense_2)\n",
        "Dense_3   = Dense(4, activation='sigmoid')(Dense_2)\n",
        "model     = Model(visible, Dense_3)\n",
        "print(model.summary())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1, 150528)]       0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 1, 1024)           618663936 \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 1024)              6295552   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 625,242,692\n",
            "Trainable params: 625,240,644\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IFe6beM66FO"
      },
      "source": [
        "sgd = SGD(learning_rate=0.01, decay = 1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "def c_loss_1(y_true, y_pred):\n",
        "    return  tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
        "\n",
        "def c_loss_2(noise_1, noise_2):\n",
        "    noise_1 = tf.cast(Dense_2 > 0.5 , tf.float32 )\n",
        "    noise_2 = Dense_2\n",
        "    return  tf.keras.losses.binary_crossentropy(noise_1, noise_2)\n",
        "model.compile(loss = [c_loss_1, c_loss_2],  optimizer=sgd, metrics=['accuracy'],)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59fLSu3v7NYR"
      },
      "source": [
        "model.fit_generator(train_generator, \n",
        "                    steps_per_epoch  = math.ceil(len(videos) // batch_size), \n",
        "                    #validation_data=val_generator,\n",
        "                    #validation_steps = math.ceil(len(val_data) // batch_size),\n",
        "                    verbose=1, \n",
        "                    epochs=300)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}